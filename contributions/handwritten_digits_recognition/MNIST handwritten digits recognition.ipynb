{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\archit\\anaconda3\\lib\\site-packages (1.19.2)\n",
      "Requirement already satisfied: sklearn in c:\\users\\archit\\anaconda3\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\archit\\anaconda3\\lib\\site-packages (from sklearn) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\archit\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\archit\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (0.17.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\archit\\anaconda3\\lib\\site-packages (from scikit-learn->sklearn) (1.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Fetching The MNIST handwrittern digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = fetch_openml('mnist_784', return_X_y=True)\n",
    "x = (x/255).astype('float64') # normalising values to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array(y, dtype=int)\n",
    "n = tmp.shape[0]\n",
    "Y = np.zeros((n, np.max(tmp) + 1), dtype=int)\n",
    "Y[np.arange(n), tmp] = 1 # converted to 70000x10 matrix where each row has 1 at index equal to target value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Dataset into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, Y, test_size=0.1, random_state=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network with forward pass and back propagation on MNIST handwritten dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self):\n",
    "        self.sizes = [784, 128, 64, 10]\n",
    "        self.epochs = 50\n",
    "        self.learning_rate = 0.001\n",
    "        self.parameters = {\n",
    "            'W1' : np.random.randn(self.sizes[1], self.sizes[0])*np.sqrt(1./self.sizes[1]),\n",
    "            'W2' : np.random.randn(self.sizes[2], self.sizes[1])*np.sqrt(1./self.sizes[2]),\n",
    "            'W3' : np.random.randn(self.sizes[3], self.sizes[2])*np.sqrt(1./self.sizes[3])\n",
    "        }\n",
    "        \n",
    "    # activation function and its derivative\n",
    "    def sigmoid(self, x):\n",
    "        return 1/(1+np.exp(-x))\n",
    "    def sigmoidDerivative(self, x):\n",
    "        return np.exp(-x)/((np.exp(-x)+1)**2)\n",
    "    \n",
    "    # calculating activations of each layer\n",
    "    def forward_pass(self, x_train):\n",
    "        params = self.parameters\n",
    "        # layer 1 / input\n",
    "        params['A0'] = x_train\n",
    "        # layer 2        \n",
    "        params['Z1'] = np.dot(params['W1'], params['A0'])\n",
    "        params['A1'] = self.sigmoid(params['Z1'])\n",
    "        # layer 3\n",
    "        params['Z2'] = np.dot(params['W2'], params['A1'])\n",
    "        params['A2'] = self.sigmoid(params['Z2'])\n",
    "        # layer 4 / output\n",
    "        params['Z3'] = np.dot(params['W3'], params['A2'])\n",
    "        params['A3'] = self.sigmoid(params['Z3'])\n",
    "        # activation of last layer is our output\n",
    "        return params['A3']\n",
    "    \n",
    "    # updating weights through back-propagation\n",
    "    def back_propagation(self, y_train, output):\n",
    "        params = self.parameters\n",
    "        change_in_weights = {} # calculates weight changes in all weights\n",
    "        \n",
    "        error3 = 2*(output-y_train)/output.shape[0] * self.sigmoidDerivative(params['Z3'])\n",
    "        change_in_weights['W3'] = np.outer(error3, params['A2'])\n",
    "        \n",
    "        error2 = np.dot(error3, params['W3'] ) * self.sigmoidDerivative(params['Z2'])\n",
    "        change_in_weights['W2'] = np.outer(error2, params['A1'])\n",
    "        \n",
    "        error1 = np.dot(error2, params['W2']) * self.sigmoidDerivative(params['Z1'])\n",
    "        change_in_weights['W1'] = np.outer(error1, params['A0'])\n",
    "        \n",
    "        return change_in_weights\n",
    "\n",
    "    # training on train-set and testing accuracy on test-set for epochs number of iterations\n",
    "    def train(self, x_train, y_train, x_val, y_val):\n",
    "        print('Training...')\n",
    "        for _iter in range(self.epochs):\n",
    "            for x,y in zip(x_train, y_train):\n",
    "                output = self.forward_pass(x)\n",
    "                changes_in_weights = self.back_propagation(y, output)\n",
    "                # updating weights depending on values returned by back propagation\n",
    "                for k,v in changes_in_weights.items():\n",
    "                    self.parameters[k] -= self.learning_rate * v                \n",
    "\n",
    "            accuracy = np.mean([np.argmax(self.forward_pass(x)) == np.argmax(y) for x,y in zip(x_test, y_test)])\n",
    "            print('Iteration: {0}\\t|\\tAccuracy: {1}%'.format(_iter+1, accuracy * 100))\n",
    "        print('\\nTraining complete!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Iteration: 1\t|\tAccuracy: 25.257142857142856%\n",
      "Iteration: 2\t|\tAccuracy: 27.514285714285712%\n",
      "Iteration: 3\t|\tAccuracy: 31.02857142857143%\n",
      "Iteration: 4\t|\tAccuracy: 35.97142857142857%\n",
      "Iteration: 5\t|\tAccuracy: 41.6%\n",
      "Iteration: 6\t|\tAccuracy: 46.62857142857143%\n",
      "Iteration: 7\t|\tAccuracy: 51.18571428571429%\n",
      "Iteration: 8\t|\tAccuracy: 54.91428571428572%\n",
      "Iteration: 9\t|\tAccuracy: 58.52857142857143%\n",
      "Iteration: 10\t|\tAccuracy: 62.671428571428564%\n",
      "Iteration: 11\t|\tAccuracy: 66.57142857142857%\n",
      "Iteration: 12\t|\tAccuracy: 69.65714285714286%\n",
      "Iteration: 13\t|\tAccuracy: 72.32857142857144%\n",
      "Iteration: 14\t|\tAccuracy: 74.31428571428572%\n",
      "Iteration: 15\t|\tAccuracy: 75.95714285714286%\n",
      "Iteration: 16\t|\tAccuracy: 77.41428571428571%\n",
      "Iteration: 17\t|\tAccuracy: 78.55714285714286%\n",
      "Iteration: 18\t|\tAccuracy: 79.31428571428572%\n",
      "Iteration: 19\t|\tAccuracy: 80.24285714285713%\n",
      "Iteration: 20\t|\tAccuracy: 81.11428571428571%\n",
      "Iteration: 21\t|\tAccuracy: 81.84285714285714%\n",
      "Iteration: 22\t|\tAccuracy: 82.52857142857142%\n",
      "Iteration: 23\t|\tAccuracy: 83.12857142857143%\n",
      "Iteration: 24\t|\tAccuracy: 83.65714285714286%\n",
      "Iteration: 25\t|\tAccuracy: 84.14285714285714%\n",
      "Iteration: 26\t|\tAccuracy: 84.65714285714286%\n",
      "Iteration: 27\t|\tAccuracy: 85.02857142857142%\n",
      "Iteration: 28\t|\tAccuracy: 85.28571428571429%\n",
      "Iteration: 29\t|\tAccuracy: 85.54285714285714%\n",
      "Iteration: 30\t|\tAccuracy: 85.78571428571429%\n",
      "Iteration: 31\t|\tAccuracy: 85.88571428571429%\n",
      "Iteration: 32\t|\tAccuracy: 86.24285714285715%\n",
      "Iteration: 33\t|\tAccuracy: 86.44285714285715%\n",
      "Iteration: 34\t|\tAccuracy: 86.61428571428571%\n",
      "Iteration: 35\t|\tAccuracy: 86.8%\n",
      "Iteration: 36\t|\tAccuracy: 86.95714285714286%\n",
      "Iteration: 37\t|\tAccuracy: 87.08571428571429%\n",
      "Iteration: 38\t|\tAccuracy: 87.27142857142857%\n",
      "Iteration: 39\t|\tAccuracy: 87.38571428571429%\n",
      "Iteration: 40\t|\tAccuracy: 87.61428571428571%\n",
      "Iteration: 41\t|\tAccuracy: 87.87142857142857%\n",
      "Iteration: 42\t|\tAccuracy: 87.97142857142856%\n",
      "Iteration: 43\t|\tAccuracy: 88.04285714285714%\n",
      "Iteration: 44\t|\tAccuracy: 88.18571428571428%\n",
      "Iteration: 45\t|\tAccuracy: 88.3%\n",
      "Iteration: 46\t|\tAccuracy: 88.34285714285714%\n",
      "Iteration: 47\t|\tAccuracy: 88.41428571428571%\n",
      "Iteration: 48\t|\tAccuracy: 88.5142857142857%\n",
      "Iteration: 49\t|\tAccuracy: 88.6%\n",
      "Iteration: 50\t|\tAccuracy: 88.67142857142856%\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork()\n",
    "nn.train(x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
